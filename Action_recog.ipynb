{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action_recog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANH3V2_3Us0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UCF101_splitter():\n",
        "    def __init__(self, path, split):\n",
        "        self.path = path\n",
        "        self.split = split\n",
        "\n",
        "    def get_action_index(self):\n",
        "        self.action_label={}\n",
        "        with open('p1.txt') as f:\n",
        "            content = f.readlines()\n",
        "            content = [x.strip('\\r\\n') for x in content]\n",
        "        f.close()\n",
        "        for line in content:\n",
        "            z=line.split(' ')\n",
        "            label=z[0]\n",
        "            z.pop(0)\n",
        "            p=' '.join(z)\n",
        "            action=p\n",
        "            #print label,action\n",
        "            if action not in self.action_label.keys():\n",
        "                self.action_label[action]=label\n",
        "\n",
        "    def split_video(self):\n",
        "        self.get_action_index()\n",
        "        for path,subdir,files in os.walk(self.path):\n",
        "            for filename in files:\n",
        "                if filename.split('.')[0] == 'trainlist'+self.split:\n",
        "                    train_video = self.file2_dic(self.path+filename)\n",
        "                if filename.split('.')[0] == 'testlist'+self.split:\n",
        "                    test_video = self.file2_dic(self.path+filename)\n",
        "        print ('==> (Training video, Validation video):(', len(train_video),len(test_video),')')\n",
        "        self.train_video = self.name_HandstandPushups(train_video)\n",
        "        self.test_video = self.name_HandstandPushups(test_video)\n",
        "\n",
        "        return self.train_video, self.test_video\n",
        "\n",
        "    def file2_dic(self,fname):\n",
        "        with open(fname) as f:\n",
        "            content = f.readlines()\n",
        "            content = [x.strip('\\r\\n') for x in content]\n",
        "        f.close()\n",
        "        dic={}\n",
        "        for line in content:\n",
        "            #print line\n",
        "            video = line.split('/',1)[1].split(' ',1)[0]\n",
        "            key = video.split('_',1)[1].split('.',1)[0]\n",
        "            label = self.action_label[line.split('/')[0]]   \n",
        "            dic[key] = int(label)\n",
        "            #print key,label\n",
        "        return dic\n",
        "\n",
        "    def name_HandstandPushups(self,dic):\n",
        "        dic2 = {}\n",
        "        for video in dic:\n",
        "            n,g = video.split('_',1)\n",
        "            if n == 'HandStandPushups':\n",
        "                videoname = 'HandstandPushups_'+ g\n",
        "            else:\n",
        "                videoname=video\n",
        "            dic2[videoname] = dic[video]\n",
        "        return dic2\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGsC_pAi4SUD",
        "colab_type": "code",
        "outputId": "089b5b16-85c8-49d1-bf69-91c312d83e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install utils\n",
        "!pip install network\n",
        "!pip install timeit\n",
        "!pip install pyttsx3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: network in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement timeit (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for timeit\u001b[0m\n",
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.6/dist-packages (2.71)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VpcIssDBf5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def draw_flow(img, flow, step=16):\n",
        "    h, w = img.shape[:2]\n",
        "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1)\n",
        "    fx, fy = flow[y, x].T\n",
        "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
        "    lines = np.int32(lines + 0.5)\n",
        "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
        "    for (x1, y1), (x2, y2) in lines:\n",
        "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
        "    return vis\n",
        "\n",
        "\n",
        "def draw_hsv(flow):\n",
        "    h, w = flow.shape[:2]\n",
        "    fx, fy = flow[:, :, 0], flow[:, :, 1]\n",
        "    ang = np.arctan2(fy, fx) + np.pi\n",
        "    v = np.sqrt(fx * fx + fy * fy)\n",
        "    hsv = np.zeros((h, w, 3), np.uint8)\n",
        "    hsv[..., 0] = ang * (180 / np.pi / 2)\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 2] = np.minimum(v * 4, 255)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    return bgr\n",
        "\n",
        "\n",
        "def opt_flow_infer(prev, img):\n",
        "\n",
        "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    cur_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_gray, cur_gray, 1, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    cv2.imshow('flow', draw_flow(cur_gray, flow))\n",
        "    cv2.imshow('flow HSV', draw_hsv(flow))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63uWa53bCM6w",
        "colab_type": "code",
        "outputId": "775a66df-1fa2-48c0-cfea-3c58605228b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class _NonLocalBlockND(nn.Module):\n",
        "    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n",
        "        super(_NonLocalBlockND, self).__init__()\n",
        "\n",
        "        assert dimension in [1, 2, 3]\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.sub_sample = sub_sample\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.inter_channels = inter_channels\n",
        "\n",
        "        if self.inter_channels is None:\n",
        "            self.inter_channels = in_channels // 2\n",
        "            if self.inter_channels == 0:\n",
        "                self.inter_channels = 1\n",
        "\n",
        "        if dimension == 3:\n",
        "            conv_nd = nn.Conv3d\n",
        "            max_pool = nn.MaxPool3d\n",
        "            bn = nn.BatchNorm3d\n",
        "        elif dimension == 2:\n",
        "            conv_nd = nn.Conv2d\n",
        "            max_pool = nn.MaxPool2d\n",
        "            bn = nn.BatchNorm2d\n",
        "        else:\n",
        "            conv_nd = nn.Conv1d\n",
        "            max_pool = nn.MaxPool1d\n",
        "            bn = nn.BatchNorm1d\n",
        "\n",
        "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                         kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if bn_layer:\n",
        "            self.W = nn.Sequential(\n",
        "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                        kernel_size=1, stride=1, padding=0),\n",
        "                bn(self.in_channels)\n",
        "            )\n",
        "            nn.init.constant(self.W[1].weight, 0)\n",
        "            nn.init.constant(self.W[1].bias, 0)\n",
        "        else:\n",
        "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "            nn.init.constant(self.W.weight, 0)\n",
        "            nn.init.constant(self.W.bias, 0)\n",
        "\n",
        "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                           kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if sub_sample:\n",
        "            self.g = nn.Sequential(self.g, max_pool(kernel_size=2))\n",
        "            self.phi = nn.Sequential(self.phi, max_pool(kernel_size=2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: (b, c, t, h, w)\n",
        "        :return:\n",
        "        '''\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
        "        g_x = g_x.permute(0, 2, 1)\n",
        "\n",
        "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
        "        theta_x = theta_x.permute(0, 2, 1)\n",
        "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
        "        f = torch.matmul(theta_x, phi_x)\n",
        "        f_div_C = F.softmax(f, dim=-1)\n",
        "\n",
        "        y = torch.matmul(f_div_C, g_x)\n",
        "        y = y.permute(0, 2, 1).contiguous()\n",
        "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
        "        W_y = self.W(y)\n",
        "        z = W_y + x\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class NONLocalBlock1D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock1D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=1, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "class NONLocalBlock2D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock2D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=2, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "class NONLocalBlock3D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock3D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=3, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from torch.autograd import Variable\n",
        "    import torch\n",
        "    sub_sample = False\n",
        "\n",
        "    img = Variable(torch.zeros(2, 4, 5))\n",
        "    net = NONLocalBlock1D(4, sub_sample=sub_sample, bn_layer=False)\n",
        "    out = net(img)\n",
        "    print(out.size())\n",
        "\n",
        "    img = Variable(torch.zeros(2, 4, 5, 3))\n",
        "    net = NONLocalBlock2D(4, sub_sample=sub_sample)\n",
        "    out = net(img)\n",
        "    print(out.size())\n",
        "\n",
        "    img = Variable(torch.zeros(2, 4, 5, 4, 5))\n",
        "    net = NONLocalBlock3D(4, sub_sample=sub_sample)\n",
        "    out = net(img)\n",
        "    print(out.size())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4, 5])\n",
            "torch.Size([2, 4, 5, 3])\n",
            "torch.Size([2, 4, 5, 4, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG4zudf7B_2t",
        "colab_type": "code",
        "outputId": "863ffc1e-1bf4-417e-8a08-479ed7b63d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "#from non_local_block import  NONLocalBlock2D\n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnet101_nln']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNetNLN(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, nb_classes=101, channel=20):\n",
        "        self.inplanes = 64\n",
        "        super(ResNetNLN, self).__init__()\n",
        "        self.conv1_custom = nn.Conv2d(channel, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc_custom = nn.Linear(512 * block.expansion, nb_classes)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        # add the NLN Block to layer\n",
        "        layers.append(NONLocalBlock2D(planes * block.expansion))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_custom(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc_custom(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, nb_classes=101, channel=3):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1_custom = nn.Conv2d(channel, 64, kernel_size=7, stride=2, padding=3,   \n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc_custom = nn.Linear(512 * block.expansion, nb_classes)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_custom(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc_custom(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, channel= 20, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet18'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, channel= 20, **kwargs):\n",
        "\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet34'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, channel= 20, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet50'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, channel=3, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3],nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet101'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101_nln(pretrained=False, channel=3, **kwargs):\n",
        "\n",
        "    model = ResNetNLN(Bottleneck, [3, 4, 23, 3],nb_classes=101, channel=channel, **kwargs)\n",
        "    if pretrained:\n",
        "       pretrain_dict = model_zoo.load_url(model_urls['resnet101'])                  # modify pretrain code\n",
        "       model_dict = model.state_dict()\n",
        "       model_dict=weight_transform(model_dict, pretrain_dict, channel)\n",
        "       model.load_state_dict(model_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "def cross_modality_pretrain(conv1_weight, channel):\n",
        "    # transform the original 3 channel weight to \"channel\" channel\n",
        "    S=0\n",
        "    for i in range(3):\n",
        "        S += conv1_weight[:,i,:,:]\n",
        "    avg = S/3.\n",
        "    new_conv1_weight = torch.FloatTensor(64,channel,7,7)\n",
        "    #print type(avg),type(new_conv1_weight)\n",
        "    for i in range(channel):\n",
        "        new_conv1_weight[:,i,:,:] = avg.data\n",
        "    return new_conv1_weight\n",
        "\n",
        "def weight_transform(model_dict, pretrain_dict, channel):\n",
        "    weight_dict  = {k:v for k, v in pretrain_dict.items() if k in model_dict}\n",
        "    #print pretrain_dict.keys()\n",
        "    w3 = pretrain_dict['conv1.weight']\n",
        "    #print type(w3)\n",
        "    if channel == 3:\n",
        "        wt = w3\n",
        "    else:\n",
        "        wt = cross_modality_pretrain(w3,channel)\n",
        "\n",
        "    weight_dict['conv1_custom.weight'] = wt\n",
        "    model_dict.update(weight_dict)\n",
        "    return model_dict\n",
        "\n",
        "#Test network\n",
        "if __name__ == '__main__':\n",
        "    model = resnet34(pretrained= True, channel=10)\n",
        "    print( model)\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1_custom): Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  (fc_custom): Linear(in_features=512, out_features=101, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zncuKFm1D86s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle,os\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from random import randint\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# other util\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint, model_best):\n",
        "    torch.save(state, checkpoint)\n",
        "    if is_best:\n",
        "        shutil.copyfile(checkpoint, model_best)\n",
        "\n",
        "def record_info(info,filename,mode):\n",
        "\n",
        "    if mode =='train':\n",
        "\n",
        "        result = (\n",
        "              'Time {batch_time} '\n",
        "              'Data {data_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5}\\n'\n",
        "              'LR {lr}\\n'.format(batch_time=info['Batch Time'],\n",
        "               data_time=info['Data Time'], loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5'],lr=info['lr']))      \n",
        "        print (result)\n",
        "\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Data Time','Loss','Prec@1','Prec@5','lr']\n",
        "        \n",
        "    if mode =='test':\n",
        "        result = (\n",
        "              'Time {batch_time} \\n'\n",
        "              'Loss {loss} '\n",
        "              'Prec@1 {top1} '\n",
        "              'Prec@5 {top5} \\n'.format( batch_time=info['Batch Time'],\n",
        "               loss=info['Loss'], top1=info['Prec@1'], top5=info['Prec@5']))      \n",
        "        print (result)\n",
        "        df = pd.DataFrame.from_dict(info)\n",
        "        column_names = ['Epoch','Batch Time','Loss','Prec@1','Prec@5']\n",
        "    \n",
        "    if not os.path.isfile(filename):\n",
        "        df.to_csv(filename,index=False,columns=column_names)\n",
        "    else: # else it exists so append without writing the header\n",
        "        df.to_csv(filename,mode = 'a',header=False,index=False,columns=column_names)   \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p003FocHtEn9",
        "colab_type": "code",
        "outputId": "3a20d267-1f16-4a5d-9bd1-e87b8fcc3980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import argparse\n",
        "import cv2\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "#import dataloader\n",
        "#from utils import *\n",
        "#from network import *\n",
        "#from dataloader import UCF101_splitter\n",
        "#from opt_flow import opt_flow_infer\n",
        "import timeit\n",
        "import pyttsx3\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "def main():\n",
        "    z='model_best.pth'\n",
        "    model = Spatial_CNN(           \n",
        "                        lr=5e-4,\n",
        "                        resume='model_best.pth.tar',\n",
        "                        demo=True\n",
        "                        )\n",
        "    model.run()\n",
        "\n",
        "\n",
        "class Spatial_CNN():\n",
        "    def __init__(self, lr,resume, demo):\n",
        "        self.lr=lr\n",
        "        self.resume=resume\n",
        "        self.demo = demo\n",
        "\n",
        "    def webcam_inference(self):\n",
        "\n",
        "        frame_count = 0\n",
        "\n",
        "        # config the transform to match the network's format\n",
        "        transform = transforms.Compose([\n",
        "                transforms.Resize((342, 256)),\n",
        "                transforms.RandomCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "        # prepare the translation dictionary label-action\n",
        "        data_handler = UCF101_splitter(os.getcwd()+'/UCF_list/', None)\n",
        "        data_handler.get_action_index()\n",
        "        class_to_idx = data_handler.action_label\n",
        "        idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "        print(idx_to_class)\n",
        "\n",
        "        # Start looping on frames received from webcam\n",
        "        vs = cv2.VideoCapture(0)\n",
        "        softmax = torch.nn.Softmax()\n",
        "\n",
        "        while True:\n",
        "            # start = time.time()\n",
        "\n",
        "            # read each frame and prepare it for feedforward in nn (resize and type)\n",
        "            ret, orig_frame = vs.read()\n",
        "\n",
        "            if ret is False:\n",
        "                print (\"Camera disconnected or not recognized by computer\")\n",
        "                break\n",
        "\n",
        "            # if frame_count == 0:\n",
        "            #     old_frame = orig_frame.copy()\n",
        "            #\n",
        "            # else:\n",
        "            #     optical_flow = opt_flow_infer(old_frame, orig_frame)\n",
        "            #     old_frame = orig_frame.copy()\n",
        "\n",
        "            frame = cv2.cvtColor(orig_frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = Image.fromarray(frame)\n",
        "            frame = transform(frame).view(1, 3, 224, 224).cpu()\n",
        "\n",
        "            # feed the frame to the neural network\n",
        "\n",
        "            # vote for class every 30 consecutive frames\n",
        "            if frame_count % 10 == 0:\n",
        "                nn_output = self.model(frame).cpu()\n",
        "                nn_output = softmax(nn_output)\n",
        "                nn_output = nn_output.data.cpu().numpy()\n",
        "                preds = nn_output.argsort()[0][-5:][::-1]\n",
        "                print(preds, \"hello\")\n",
        "                pred_classes = [(idx_to_class[str(pred+1)], nn_output[0, pred]) for pred in preds]\n",
        "                print(pred_classes[0][0])\n",
        "                engine = pyttsx3.init()\n",
        "                engine.say(pred_classes[0][0])\n",
        "                engine.runAndWait()\n",
        "\n",
        "            # Display the resulting frame and the classified action\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            y0, dy = 300, 40\n",
        "            for i in range(3):\n",
        "                y = y0 + i * dy\n",
        "                cv2.putText(orig_frame, '{} - {:.2f}'.format(pred_classes[i][0], pred_classes[i][1]),\n",
        "                            (5, y), font, 1, (0, 0, 255), 2)\n",
        "                #print('{} - {:.2f}'.format(pred_classes[i][0], pred_classes[i][1]))\n",
        "            #print(pred_classes[0][0])\n",
        "            k=pred_classes[0][0]\n",
        "            cv2.imshow('Webcam', orig_frame)\n",
        "            frame_count += 1\n",
        "            # end = time.time()\n",
        "            # print (end - start)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # When everything done, release the capture\n",
        "        vs.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        print ('==> Build model and setup loss and optimizer')\n",
        "        #build model\n",
        "        self.model = resnet101(pretrained= True, channel=3).cpu()\n",
        "        #Loss function and optimizer\n",
        "        self.criterion = nn.CrossEntropyLoss().cpu()\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), self.lr, momentum=0.9)\n",
        "        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=1,verbose=True)\n",
        "\n",
        "    def resume_and_evaluate(self):\n",
        "        if self.resume:\n",
        "            if os.path.isfile(self.resume):\n",
        "                print(\"==> loading checkpoint '{}'\".format(self.resume))\n",
        "                map_location=torch.device('cpu')\n",
        "                checkpoint = torch.load(self.resume,map_location=torch.device('cpu'))\n",
        "                self.start_epoch = checkpoint['epoch']\n",
        "                self.best_prec1 = checkpoint['best_prec1']\n",
        "                self.model.load_state_dict(checkpoint['state_dict'])\n",
        "                self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "                print(\"==> loaded checkpoint '{}' (epoch {}) (best_prec1 {})\"\n",
        "                  .format(self.resume, checkpoint['epoch'], self.best_prec1))\n",
        "           # else:\n",
        "            #    print(\"==> no checkpoint found at '{}'\".format(self.resume))\n",
        "        #if self.evaluate:\n",
        "         #   self.epoch = 0\n",
        "          #  prec1, val_loss = self.validate_1epoch()\n",
        "           # return\n",
        "\n",
        "        if self.demo:\n",
        "            print('1')\n",
        "            self.model.eval()\n",
        "            print('2')\n",
        "            self.webcam_inference()\n",
        "\n",
        "    def run(self):\n",
        "        self.build_model()\n",
        "        self.resume_and_evaluate()\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "        if self.demo:\n",
        "            print(\"Entered\")\n",
        "            self.resume_and_evaluate()\n",
        "\n",
        "        \n",
        "    def frame2_video_level_accuracy(self):\n",
        "\n",
        "        correct = 0\n",
        "        video_level_preds = np.zeros((len(self.dic_video_level_preds),101))\n",
        "        video_level_labels = np.zeros(len(self.dic_video_level_preds))\n",
        "        ii=0\n",
        "        for name in sorted(self.dic_video_level_preds.keys()):\n",
        "\n",
        "            preds = self.dic_video_level_preds[name]\n",
        "            label = int(self.test_video[name])-1\n",
        "\n",
        "            video_level_preds[ii,:] = preds\n",
        "            video_level_labels[ii] = label\n",
        "            ii+=1\n",
        "            if np.argmax(preds) == (label):\n",
        "                correct+=1\n",
        "\n",
        "        #top1 top5\n",
        "        video_level_labels = torch.from_numpy(video_level_labels).long()\n",
        "        video_level_preds = torch.from_numpy(video_level_preds).float()\n",
        "\n",
        "        top1,top5 = accuracy(video_level_preds, video_level_labels, topk=(1,5))\n",
        "        loss = self.criterion(Variable(video_level_preds).cpu(), Variable(video_level_labels).cpu())\n",
        "\n",
        "        top1 = float(top1.numpy())\n",
        "        top5 = float(top5.numpy())\n",
        "\n",
        "        #print(' * Video level Prec@1 {top1:.3f}, Video level Prec@5 {top5:.3f}'.format(top1=top1, top5=top5))\n",
        "        return top1,top5,loss.data.cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__': #output as success or failure, if successful, get the top three actions\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Build model and setup loss and optimizer\n",
            "==> loading checkpoint 'model_best.pth.tar'\n",
            "==> loaded checkpoint 'model_best.pth.tar' (epoch 31) (best_prec1 82.13058471679688)\n",
            "1\n",
            "2\n",
            "{'1': 'Person is applying eye makeup.', '2': 'Person is applying Lipstick.', '3': 'Person is practicing archery.', '4': 'Baby is crawling .', '5': 'Person is working on balance beam.', '6': 'Person is looking at the band marching.', '7': 'People are palying on baseball pitch.', '8': 'Person is playing basketball.', '9': 'People are playing with basketball dunk.', '10': 'Person is working out on a bench press.', '11': 'Person is enjoying biking.', '12': 'Person is playing billards.', '13': 'Person is blowing her dry hair.', '14': 'Person is blowing candles.', '15': 'Person is working out with body weight squats.', '16': 'Person is bowling.', '17': 'Person is boxing the punching bag.', '18': 'Person is boxing with the speed bag.', '19': 'Person is working on breaststroke technique.', '20': 'Person is brushing teeth.', '21': 'Person is working on Clean and Jerk technique.', '22': 'Person is working on cliff diving technique.', '23': 'Person is bowling in game of cricket', '24': 'Person has blown a shot in game of cricket.', '25': 'Person is cutting in kitchen.', '26': 'Person is diving.', '27': 'Person is drumming.', '28': 'Person is enjoying fencing.', '29': 'Person has been imposed penalty in field hockey.', '30': 'Person is practicinf floor gymnastics.', '31': 'Person is working on Frisbee catch.', '32': 'Person is working on front crawl technique.', '33': 'Person is working on golf swing.', '34': 'Person is undergoing haircut.', '35': 'Person is hammerring something.', '36': 'Person is working on hammer throw technique.', '37': 'Person is working upon handstand pushups.', '38': 'Person is working on handstand technique.', '39': 'Person is undergoing head massage.', '40': 'Person is working on high jump.', '41': 'Person is enjoying in horse race.', '42': 'Person is participating in horseriding.', '43': 'Person is working on Hula hoop.', '44': 'Person is enjoying Ice dancing.', '45': 'Person is working on Javelin throw.', '46': 'Person is working on Juggling Balls.', '47': 'Person is working on jumping jack technique.', '48': 'Person is working on jumping rope.', '49': 'Person is enjoying the kaying sport.', '50': 'Person is knitting the clothes.', '51': 'Person is working on long jump.', '52': 'Person is working out on lunges.', '53': 'There is a military parade going on.', '54': 'Person is mixing something.', '55': 'Person is mopping the floor.', '56': 'Person is working on Nunchucks technique.', '57': 'Person is working on parallel bars.', '58': 'Person is tossing a pizza.', '59': 'Person is playing a cello.', '60': 'Person is playing a Daf.', '61': 'Person is playing a Dhol.', '62': 'Person is playing a flute.', '63': 'Person is playing a Guitar.', '64': 'Person is playing a Piano.', '65': 'Person is playing a Sitar.', '66': 'Person is playing a tabla.', '67': 'Person is palying a Violin.', '68': 'Person is working on Pole Vault.', '69': 'Person is working with a Pommel Horse.', '70': 'Person is working on pull ups.', '71': 'Person is working on punches.', '72': 'Person is working on push ups.', '73': 'Person is enjoying rafting.', '74': 'Person is working on indooe rock climbing.', '75': 'Person is enjoying rope climbing.', '76': 'Person is enjoying rowing.', '77': 'Person is working on SalaSpin technique.', '78': 'Person is shaving his beard.', '79': 'Person is working on shotput technique.', '80': 'Person is practicing Skate boarding.', '81': 'Person is working on skiing techniques.', '82': 'Person is enjoying skijet sport.', '83': 'Person is enjoying skydiving sport.', '84': 'Person is working on Soccer Juggling techniques.', '85': 'Soccer penalty is being currently executed.', '86': 'Person is working on StillRings sport.', '87': 'Person is working on sumo wrestling.', '88': 'Person is working on techniques of Surfing sport.', '89': 'Person is enjoying the swing.', '90': 'Person is practicing table tennis shots.', '91': 'Person is practicing TaiChi.', '92': 'Person is practicing tennis swing techniques.', '93': 'Person is practicing discuss throwing.', '94': 'person is working on Trampoline jumping.', '95': 'Person is typing.', '96': 'Person is working on techniques of UnevenBars,', '97': 'Person is working upon Volleyball spiking.', '98': 'Person is walking with a dog,', '99': 'Person is working out with wall pushups.', '100': 'Person is writing on board.', '101': 'Person is working on yoyo techniques.', '': ''}\n",
            "Camera disconnected or not recognized by computer\n",
            "Entered\n",
            "==> loading checkpoint 'model_best.pth.tar'\n",
            "==> loaded checkpoint 'model_best.pth.tar' (epoch 31) (best_prec1 82.13058471679688)\n",
            "1\n",
            "2\n",
            "{'1': 'Person is applying eye makeup.', '2': 'Person is applying Lipstick.', '3': 'Person is practicing archery.', '4': 'Baby is crawling .', '5': 'Person is working on balance beam.', '6': 'Person is looking at the band marching.', '7': 'People are palying on baseball pitch.', '8': 'Person is playing basketball.', '9': 'People are playing with basketball dunk.', '10': 'Person is working out on a bench press.', '11': 'Person is enjoying biking.', '12': 'Person is playing billards.', '13': 'Person is blowing her dry hair.', '14': 'Person is blowing candles.', '15': 'Person is working out with body weight squats.', '16': 'Person is bowling.', '17': 'Person is boxing the punching bag.', '18': 'Person is boxing with the speed bag.', '19': 'Person is working on breaststroke technique.', '20': 'Person is brushing teeth.', '21': 'Person is working on Clean and Jerk technique.', '22': 'Person is working on cliff diving technique.', '23': 'Person is bowling in game of cricket', '24': 'Person has blown a shot in game of cricket.', '25': 'Person is cutting in kitchen.', '26': 'Person is diving.', '27': 'Person is drumming.', '28': 'Person is enjoying fencing.', '29': 'Person has been imposed penalty in field hockey.', '30': 'Person is practicinf floor gymnastics.', '31': 'Person is working on Frisbee catch.', '32': 'Person is working on front crawl technique.', '33': 'Person is working on golf swing.', '34': 'Person is undergoing haircut.', '35': 'Person is hammerring something.', '36': 'Person is working on hammer throw technique.', '37': 'Person is working upon handstand pushups.', '38': 'Person is working on handstand technique.', '39': 'Person is undergoing head massage.', '40': 'Person is working on high jump.', '41': 'Person is enjoying in horse race.', '42': 'Person is participating in horseriding.', '43': 'Person is working on Hula hoop.', '44': 'Person is enjoying Ice dancing.', '45': 'Person is working on Javelin throw.', '46': 'Person is working on Juggling Balls.', '47': 'Person is working on jumping jack technique.', '48': 'Person is working on jumping rope.', '49': 'Person is enjoying the kaying sport.', '50': 'Person is knitting the clothes.', '51': 'Person is working on long jump.', '52': 'Person is working out on lunges.', '53': 'There is a military parade going on.', '54': 'Person is mixing something.', '55': 'Person is mopping the floor.', '56': 'Person is working on Nunchucks technique.', '57': 'Person is working on parallel bars.', '58': 'Person is tossing a pizza.', '59': 'Person is playing a cello.', '60': 'Person is playing a Daf.', '61': 'Person is playing a Dhol.', '62': 'Person is playing a flute.', '63': 'Person is playing a Guitar.', '64': 'Person is playing a Piano.', '65': 'Person is playing a Sitar.', '66': 'Person is playing a tabla.', '67': 'Person is palying a Violin.', '68': 'Person is working on Pole Vault.', '69': 'Person is working with a Pommel Horse.', '70': 'Person is working on pull ups.', '71': 'Person is working on punches.', '72': 'Person is working on push ups.', '73': 'Person is enjoying rafting.', '74': 'Person is working on indooe rock climbing.', '75': 'Person is enjoying rope climbing.', '76': 'Person is enjoying rowing.', '77': 'Person is working on SalaSpin technique.', '78': 'Person is shaving his beard.', '79': 'Person is working on shotput technique.', '80': 'Person is practicing Skate boarding.', '81': 'Person is working on skiing techniques.', '82': 'Person is enjoying skijet sport.', '83': 'Person is enjoying skydiving sport.', '84': 'Person is working on Soccer Juggling techniques.', '85': 'Soccer penalty is being currently executed.', '86': 'Person is working on StillRings sport.', '87': 'Person is working on sumo wrestling.', '88': 'Person is working on techniques of Surfing sport.', '89': 'Person is enjoying the swing.', '90': 'Person is practicing table tennis shots.', '91': 'Person is practicing TaiChi.', '92': 'Person is practicing tennis swing techniques.', '93': 'Person is practicing discuss throwing.', '94': 'person is working on Trampoline jumping.', '95': 'Person is typing.', '96': 'Person is working on techniques of UnevenBars,', '97': 'Person is working upon Volleyball spiking.', '98': 'Person is walking with a dog,', '99': 'Person is working out with wall pushups.', '100': 'Person is writing on board.', '101': 'Person is working on yoyo techniques.', '': ''}\n",
            "Camera disconnected or not recognized by computer\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
